{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPwsIv8nGJxg8lx5E93Iu9t"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FgCvdNjkrgux","executionInfo":{"status":"ok","timestamp":1742778296923,"user_tz":0,"elapsed":5868,"user":{"displayName":"Hridya A","userId":"15414288690859197299"}},"outputId":"05f22089-7d33-483c-8884-9d3486d91dca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 100.00%\n","\n","Confusion Matrix:\n","[[10  0  0]\n"," [ 0  9  0]\n"," [ 0  0 11]]\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        10\n","           1       1.00      1.00      1.00         9\n","           2       1.00      1.00      1.00        11\n","\n","    accuracy                           1.00        30\n","   macro avg       1.00      1.00      1.00        30\n","weighted avg       1.00      1.00      1.00        30\n","\n"]}],"source":["# Import necessary libraries\n","import pandas as pd\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","# Step 1: Load the Iris dataset\n","iris = load_iris()\n","X = iris.data  # Features\n","y = iris.target  # Target labels\n","\n","# Step 2: Split the dataset into training and testing sets (80% train, 20% test)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Step 3: Create a logistic regression model\n","model = LogisticRegression(max_iter=200)\n","\n","# Step 4: Train the model on the training set\n","model.fit(X_train, y_train)\n","\n","# Step 5: Predict the target values on the test set\n","y_pred = model.predict(X_test)\n","\n","# Step 6: Evaluate the model\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Accuracy: {accuracy * 100:.2f}%')\n","\n","print(\"\\nConfusion Matrix:\")\n","print(confusion_matrix(y_test, y_pred))\n","\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_test, y_pred))\n"]},{"cell_type":"markdown","source":["The results you've shared show that the logistic regression model performed perfectly on the test dataset. Letâ€™s break down what each part means:\n","\n","Accuracy: 100.00%   \n","This indicates that the model correctly predicted all of the test samples. The accuracy is the ratio of correctly predicted instances to the total instances. Here, a value of 100% suggests that no misclassifications occurred.\n","\n","Confusion Matrix:   \n","lua\n","Copy\n","Edit\n","[[10  0  0]\n"," [ 0  9  0]\n"," [ 0  0 11]]\n","The confusion matrix is a table that shows the performance of the model on the test set. It breaks down predictions by class, comparing the predicted labels (columns) with the true labels (rows).\n","\n","In this case, for the Iris dataset:   \n","\n","Class 0: The model correctly predicted 10 instances as class 0 and made no misclassifications.\n","\n","Class 1: The model correctly predicted 9 instances as class 1, with no misclassifications.\n","\n","Class 2: The model correctly predicted 11 instances as class 2, with no misclassifications.\n","\n","The matrix shows that each instance was correctly classified, with no false positives or false negatives.\n","\n","Classification Report:    \n","The classification report gives a detailed breakdown of how the model performed for each class. Key metrics include:\n","\n","Precision: Measures the accuracy of the positive predictions.\n","\n","For example, the precision for class 0 is 1.00, meaning that every time the model predicted class 0, it was correct.\n","\n","Recall: Measures the ability of the model to find all positive instances of each class.\n","\n","For class 0, recall is 1.00, meaning the model identified all instances of class 0 correctly.\n","\n","F1-Score: The harmonic mean of precision and recall, offering a balanced view of the model's performance.\n","\n","The F1-score for each class is 1.00, which indicates a perfect balance between precision and recall.\n","\n","Support: The number of true instances for each class in the test set. For instance:\n","\n","Class 0 had 10 instances in the test set.\n","\n","Class 1 had 9 instances.\n","\n","Class 2 had 11 instances.\n","\n","The macro avg and weighted avg are averages across all classes:\n","\n","Macro avg gives the unweighted mean of precision, recall, and F1-score, treating each class equally.\n","\n","Weighted avg takes into account the support (number of instances) for each class, giving more weight to classes with more instances.\n","\n","In summary:   \n","Perfect Performance: The model has achieved a perfect score (100% accuracy) on this dataset.\n","\n","Confusion Matrix: There are no misclassifications, with all samples correctly assigned to their respective classes.\n","\n","Classification Report: The model has perfect precision, recall, and F1-scores across all classes.\n","\n","This is an excellent result and suggests that the model has generalized well for the Iris dataset. However, this perfect result could be specific to the dataset's simplicity and might not be typical for more complex real-world datasets.\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"ieJrFwYKsAUV"}},{"cell_type":"code","source":[],"metadata":{"id":"ZsKCY-i6sBM-"},"execution_count":null,"outputs":[]}]}